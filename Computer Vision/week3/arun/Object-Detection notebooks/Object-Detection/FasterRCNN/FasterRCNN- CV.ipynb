{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FasterRCNN- CV.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"S3jNdzVVAX-0","colab_type":"text"},"source":["## Object detection\n","\n","In this case study, we will be knowing how to pre-trained models to do object detection"]},{"cell_type":"markdown","metadata":{"id":"qMkofzI3CaUj","colab_type":"text"},"source":["### Setup\n","- We will need 'pycocotools' package"]},{"cell_type":"code","metadata":{"id":"7Mh2theJAay-","colab_type":"code","outputId":"5c492e12-8f32-4b12-d1fa-ddf2dc5916a5","executionInfo":{"status":"ok","timestamp":1587871869299,"user_tz":-330,"elapsed":5030,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install pycocotools"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S9gN7y9FDIlm","colab_type":"text"},"source":["- We need to have 'tensorflow/models' from github to get all the pre-trained models"]},{"cell_type":"code","metadata":{"id":"mkX2kT5PCxs-","colab_type":"code","outputId":"f778b7a3-98d8-4f42-9e0a-5903c5974dc5","executionInfo":{"status":"ok","timestamp":1587871878691,"user_tz":-330,"elapsed":14409,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["!git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'models'...\n","remote: Enumerating objects: 2571, done.\u001b[K\n","remote: Counting objects: 100% (2571/2571), done.\u001b[K\n","remote: Compressing objects: 100% (2237/2237), done.\u001b[K\n","remote: Total 2571 (delta 504), reused 1392 (delta 297), pack-reused 0\u001b[K\n","Receiving objects: 100% (2571/2571), 124.07 MiB | 32.59 MiB/s, done.\n","Resolving deltas: 100% (504/504), done.\n","Checking out files: 100% (2483/2483), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WAOFykOuEuvi","colab_type":"text"},"source":["- Now let's install the object detection package"]},{"cell_type":"code","metadata":{"id":"vaksN_-xDSRg","colab_type":"code","colab":{}},"source":["%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNy7nFSLE7DP","colab_type":"code","outputId":"cda591c8-85e6-4ca7-f3ef-d9c1e999c640","executionInfo":{"status":"ok","timestamp":1587871883717,"user_tz":-330,"elapsed":19412,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["%%bash \n","cd models/research\n","pip install ."],"execution_count":5,"outputs":[{"output_type":"stream","text":["Processing /content/models/research\n","Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n","Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.1)\n","Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.16)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->Matplotlib>=2.1->object-detection==0.1) (1.12.0)\n","Building wheels for collected packages: object-detection\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1017525 sha256=2872fe3d272a715444496e997b1bdb9d481ad8d0c45dcb802e2f8ca959368c62\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r2d6lqj0/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n","Successfully built object-detection\n","Installing collected packages: object-detection\n","Successfully installed object-detection-0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AxB5gKEhFRk1","colab_type":"text"},"source":["### Let's do the imports now\n","- Import tensorflow and other modules"]},{"cell_type":"code","metadata":{"id":"CHQqCTP3Fay6","colab_type":"code","outputId":"5df3fbce-abc9-4d39-830d-395d7c608b88","executionInfo":{"status":"ok","timestamp":1587871885198,"user_tz":-330,"elapsed":20883,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 2.x\n","import tensorflow\n","tensorflow.__version__"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.2.0-rc3'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"L7JWlwWXE88T","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","from IPython.display import display"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Wq731RMF2Ob","colab_type":"text"},"source":["- Import the object detection modules"]},{"cell_type":"code","metadata":{"id":"qBD4DAgLFsIq","colab_type":"code","colab":{}},"source":["from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y2QZ_KKZGPJc","colab_type":"text"},"source":["- Patches"]},{"cell_type":"code","metadata":{"id":"HfK68txKF8AP","colab_type":"code","colab":{}},"source":["# patch tf1 into `utils.ops`\n","utils_ops.tensorflow = tensorflow.compat.v1\n","\n","# Patch the location of gfile\n","tensorflow.gfile = tensorflow.io.gfile"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rfRJW0OSGlgZ","colab_type":"text"},"source":["### Model prepration"]},{"cell_type":"markdown","metadata":{"id":"qjlrmpnJGwOh","colab_type":"text"},"source":["#### **Variables**\n","- We will be using faster rcnn model by default. You can check out the entire list of models from here https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"]},{"cell_type":"markdown","metadata":{"id":"3HbywmTZHF1J","colab_type":"text"},"source":["#### **Model loader**"]},{"cell_type":"code","metadata":{"id":"6WCUBL7eGRiI","colab_type":"code","colab":{}},"source":["def load_model(model_name):\n","  base_url = 'http://download.tensorflow.org/models/object_detection/'\n","  model_file = model_name + '.tar.gz'\n","  model_dir = tensorflow.keras.utils.get_file(\n","    fname=model_name, \n","    origin=base_url + model_file,\n","    untar=True)\n","\n","  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n","\n","  model = tensorflow.saved_model.load(str(model_dir))\n","  model = model.signatures['serving_default']\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qa1_usHaHdVl","colab_type":"text"},"source":["#### **Load the label map**\n","- Every category is mapped to a certain label. Let's load the file which contains all the mappings"]},{"cell_type":"code","metadata":{"id":"-2CeWbzHHO6k","colab_type":"code","colab":{}},"source":["# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPGdWPjttA9U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"9d323981-6bcc-4edc-eb76-758fc464176e","executionInfo":{"status":"ok","timestamp":1587874865982,"user_tz":-330,"elapsed":32453,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mWh37I4iHpRQ","colab_type":"code","outputId":"7a9b61f7-733d-4cc0-eea4-8f99b8cb3c20","executionInfo":{"status":"ok","timestamp":1587871885207,"user_tz":-330,"elapsed":20864,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n","import pathlib\n","PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n","TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n","TEST_IMAGE_PATHS"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PosixPath('models/research/object_detection/test_images/image1.jpg'),\n"," PosixPath('models/research/object_detection/test_images/image2.jpg')]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"BoJK_sWtN4Z8","colab_type":"text"},"source":["### Detection\n","- Let's load an object detection model"]},{"cell_type":"code","metadata":{"id":"iN4H1Y8oH0sM","colab_type":"code","outputId":"f7ef9627-24a6-4525-f00c-ffc260d45aad","executionInfo":{"status":"ok","timestamp":1587871927520,"user_tz":-330,"elapsed":63168,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["model_name = 'faster_rcnn_nas_coco_2018_01_28'\n","detection_model = load_model(model_name)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Downloading data from http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2018_01_28.tar.gz\n","1173757952/1173756273 [==============================] - 10s 0us/step\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L3fdycnLOKYZ","colab_type":"text"},"source":["- Let's see what kind of input this models takes"]},{"cell_type":"code","metadata":{"id":"PckufpVUN-g0","colab_type":"code","outputId":"26fde409-368e-4521-ac54-e099a4802044","executionInfo":{"status":"ok","timestamp":1587871927522,"user_tz":-330,"elapsed":63159,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["detection_model.inputs"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor 'image_tensor:0' shape=(None, None, None, 3) dtype=uint8>]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"nEy7U_32OwJQ","colab_type":"text"},"source":["- Let's see what this model outputs"]},{"cell_type":"code","metadata":{"id":"BQXmNnjpOIw-","colab_type":"code","outputId":"ef518168-7cc4-4045-f02f-94f3dfc4c470","executionInfo":{"status":"ok","timestamp":1587871927524,"user_tz":-330,"elapsed":63153,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["detection_model.output_shapes"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'detection_boxes': TensorShape([None, 100, 4]),\n"," 'detection_classes': TensorShape([None, 100]),\n"," 'detection_scores': TensorShape([None, 100]),\n"," 'num_detections': TensorShape([None])}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"cie01jLFPFld","colab_type":"text"},"source":["- Function to call the model and clean the output"]},{"cell_type":"code","metadata":{"id":"HT8tPTXbOzge","colab_type":"code","colab":{}},"source":["def run_inference_for_single_image(model, image):\n","  image = np.asarray(image)\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tensorflow.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tensorflow.newaxis,...]\n","\n","  # Run inference\n","  output_dict = model(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(output_dict.pop('num_detections'))\n","  output_dict = {key:value[0, :num_detections].numpy() \n","                 for key,value in output_dict.items()}\n","  output_dict['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","   \n","  # Handle models with masks:\n","  if 'detection_masks' in output_dict:\n","    # Reframe the the bbox mask to the image size.\n","    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","              output_dict['detection_masks'], output_dict['detection_boxes'],\n","               image.shape[0], image.shape[1])      \n","    detection_masks_reframed = tensorflow.cast(detection_masks_reframed > 0.5,\n","                                       tensorflow.uint8)\n","    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    \n","  return output_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K5v8EqwsPWIY","colab_type":"text"},"source":["- Function to display the results for each input"]},{"cell_type":"code","metadata":{"id":"IiYgiGvNPQWQ","colab_type":"code","colab":{}},"source":["def show_inference(model, image_path):\n","  # the array based representation of the image will be used later in order to prepare the\n","  # result image with boxes and labels on it.\n","  image_np = np.array(Image.open(image_path))\n","  # Actual detection.\n","  output_dict = run_inference_for_single_image(model, image_np)\n","  # Visualization of the results of a detection.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks_reframed', None),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","\n","  display(Image.fromarray(image_np))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fR9csqALPg9v","colab_type":"code","outputId":"9332a201-db76-42fc-d8af-98fafe6942cd","executionInfo":{"status":"ok","timestamp":1587872101113,"user_tz":-330,"elapsed":236726,"user":{"displayName":"arun sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXAgcS1k4-TwDIb88TlK3TU72ypvmuvASeEj3P6A=s64","userId":"08295320584314104136"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1IIVLPI9_wQNXEsltLd17eaNJQsbUADme"}},"source":["for image_path in TEST_IMAGE_PATHS:\n","  show_inference(detection_model, image_path)"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"gMfSyBuLEq0b","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}